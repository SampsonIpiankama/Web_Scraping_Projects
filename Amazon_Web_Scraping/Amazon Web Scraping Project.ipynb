{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b1bcfb",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3ae822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e512e",
   "metadata": {},
   "source": [
    "# Startup Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22f39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Selenium drivers\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51033b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c12eea",
   "metadata": {},
   "source": [
    "### Create a function that will insert a search term using string formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33dbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(search_term):\n",
    "    \"\"\"generate a url from search term\"\"\"\n",
    "    template = \"https://www.amazon.com/s?k={}&crid=27E68Q3L17CGO&sprefix=data+%2Caps%2C420&ref=nb_sb_ss_ts-doa-p_2_5\"\n",
    "    search_term = search_term.replace( \" \", \"+\")\n",
    "    return template.format(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d18c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/s?k=data+analysis&crid=27E68Q3L17CGO&sprefix=data+%2Caps%2C420&ref=nb_sb_ss_ts-doa-p_2_5\n"
     ]
    }
   ],
   "source": [
    "url = get_url(\"data analysis\")\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ea97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76965803",
   "metadata": {},
   "source": [
    "## Extract page contents from the HTML in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24541213",
   "metadata": {},
   "source": [
    "### Step 1: create soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feed28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063536ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac16d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e960b56",
   "metadata": {},
   "source": [
    "### Step 2: Extract a single record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016463d9",
   "metadata": {},
   "source": [
    "What I need\n",
    "1. Book_name\n",
    "2. url\n",
    "3. Price\n",
    "4. Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d072b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20acf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "atag = item.h2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb6e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name =atag.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37b56b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.com\" + atag.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d4e5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_parent = item.find(\"span\", \"a-price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e1ef7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price_parent.find(\"span\", \"a-offscreen\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb49ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = item.i.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743cf99",
   "metadata": {},
   "source": [
    "### Step 3: Write a function that includes all other records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69e1d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record\"\"\"\n",
    "    \n",
    "    # book_name and url\n",
    "    atag = item.h2.a\n",
    "    book_name = atag.text.strip()\n",
    "    url = \"https://www.amazon.com\" + atag.get(\"href\")\n",
    "    \n",
    "    # price\n",
    "    price_parent = item.find(\"span\", \"a-price\")\n",
    "    price = price_parent.find(\"span\", \"a-offscreen\").text\n",
    "    \n",
    "       \n",
    "    # rating \n",
    "    rating = item.i.text\n",
    "        \n",
    "    \n",
    "    \"\"\"I'll create a tuple that contains these items and i'll assign it to a result variable and I'll return the tuple as a result \"\"\"\n",
    "    result = (book_name, price, rating, url)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69147e7",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267a847",
   "metadata": {},
   "source": [
    "1. Create a records list that is empty that will contain all of our extracted records.\n",
    "2. Use the results pattern above to collect all the results on the page to iterate through.\n",
    "3. Check to see if the record list is empty or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a19f172",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAMPSO~1.IPI\\AppData\\Local\\Temp/ipykernel_1696/1706533217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mrecords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SAMPSO~1.IPI\\AppData\\Local\\Temp/ipykernel_1696/2906948672.py\u001b[0m in \u001b[0;36mextract_record\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# price\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprice_parent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a-price\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprice_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a-offscreen\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "results = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\" })\n",
    "\n",
    "for item in results:\n",
    "        records.append(extract_record(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "774773ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record\"\"\"\n",
    "    \n",
    "    # book_name and url\n",
    "    atag = item.h2.a\n",
    "    book_name = atag.text.strip()\n",
    "    url = \"https://www.amazon.com\" + atag.get(\"href\")\n",
    "    \n",
    "    try:\n",
    "        # price\n",
    "        price_parent = item.find(\"span\", \"a-price\")\n",
    "        price = price_parent.find(\"span\", \"a-offscreen\").text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    try:   \n",
    "        # rating \n",
    "        rating = item.i.text\n",
    "    except AttributeError:\n",
    "        rating = \" \"\n",
    "        \n",
    "    \n",
    "    \"\"\"I'll create a tuple that contains these items and i'll assign it to a result variable and I'll return the tuple as a result \"\"\"\n",
    "    result = (book_name, price, rating, url)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab9f0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "results = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\" })\n",
    "\n",
    "for item in results:\n",
    "    record = extract_record(item)\n",
    "    if record:\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e07b9f",
   "metadata": {},
   "source": [
    "#### Print the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94d53b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Storytelling with Data: A Data Visualization Guide for Business Professionals',\n",
       " '$19.25',\n",
       " '4.6 out of 5 stars',\n",
       " 'https://www.amazon.com/Storytelling-Data-Visualization-Business-Professionals/dp/1119002257/ref=sr_1_1?crid=27E68Q3L17CGO&keywords=data+analysis&qid=1639655944&sprefix=data+%2Caps%2C420&sr=8-1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb083bd",
   "metadata": {},
   "source": [
    "#### Print the prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e48a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$19.25\n",
      "$49.99\n",
      "$14.00\n",
      "$50.14\n",
      "$55.24\n",
      "$80.75\n",
      "$11.92\n",
      "$38.37\n",
      "$35.89\n",
      "$15.60\n",
      "$37.80\n",
      "$36.78\n",
      "$23.95\n",
      "$27.80\n",
      "$33.48\n",
      "$27.58\n",
      "$19.47\n",
      "$35.71\n",
      "$44.94\n",
      "$30.54\n",
      "$40.49\n",
      "$35.13\n",
      "$22.99\n",
      "$15.90\n",
      "$30.32\n",
      "$27.26\n",
      "$29.95\n",
      "$28.33\n",
      "$39.99\n",
      "$17.99\n",
      "$56.72\n",
      "$37.74\n",
      "$115.00\n",
      "$18.59\n",
      "$18.99\n",
      "$33.24\n",
      "$34.99\n",
      "$40.10\n",
      "$53.62\n",
      "$43.96\n",
      "$40.00\n",
      "$46.54\n",
      "$17.97\n",
      "$32.88\n"
     ]
    }
   ],
   "source": [
    "for row in records:\n",
    "    print(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26724a5",
   "metadata": {},
   "source": [
    "## Scrape Multiple Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40fda158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(search_term):\n",
    "    \"\"\"generate a url from search term\"\"\"\n",
    "    template = \"https://www.amazon.com/s?k={}&crid=27E68Q3L17CGO&sprefix=data+%2Caps%2C420&ref=nb_sb_ss_ts-doa-p_2_5\"\n",
    "    search_term = search_term.replace( \" \", \"+\")\n",
    "    \n",
    "    \n",
    "    #add term query to url\n",
    "    url = template.format(search_term)\n",
    "    \n",
    "    #add page query placeholder\n",
    "    url += \"&page={}\"\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa20b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "def get_url(search_term):\n",
    "    \"\"\"generate a url from search term\"\"\"\n",
    "    template = \"https://www.amazon.com/s?k={}&crid=27E68Q3L17CGO&sprefix=data+%2Caps%2C420&ref=nb_sb_ss_ts-doa-p_2_5\"\n",
    "    search_term = search_term.replace( \" \", \"+\")\n",
    "    \n",
    "    \n",
    "    #add term query to url\n",
    "    url = template.format(search_term)\n",
    "    \n",
    "    #add page query placeholder\n",
    "    url += \"&page={}\"\n",
    "    \n",
    "    return url\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and return data from a single record\"\"\"\n",
    "    \n",
    "    # book_name and url\n",
    "    atag = item.h2.a\n",
    "    book_name = atag.text.strip()\n",
    "    url = \"https://www.amazon.com\" + atag.get(\"href\")\n",
    "    \n",
    "    try:\n",
    "        # price\n",
    "        price_parent = item.find(\"span\", \"a-price\")\n",
    "        price = price_parent.find(\"span\", \"a-offscreen\").text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    try:   \n",
    "        # rating \n",
    "        rating = item.i.text\n",
    "    except AttributeError:\n",
    "        rating = \" \"\n",
    "        \n",
    "    \n",
    "    #I'll create a tuple that contains these items and i'll assign it to a result variable and I'll return the tuple as a result \"\"\"\n",
    "    result = (book_name, price, rating, url)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main(search_term):\n",
    "    #run main program\"\"\"\n",
    "    #startup webdriver\n",
    "    driver = webdriver.Chrome(\"C:\\Selenium drivers\\chromedriver.exe\")\n",
    "    \n",
    "    #create the records list and set a url with our search term that we already passed to the main function\"\"\"\n",
    "    records = []\n",
    "    url = get_url(search_term)\n",
    "    \n",
    "     \n",
    "    for page in range (1, 8):\n",
    "        driver.get(url.format(page))\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\" })\n",
    "        print(page)\n",
    "        \n",
    "         # for each of the results, extract the records data and append it to the record's list\n",
    "        for item in results:\n",
    "            record = extract_record(item)\n",
    "            if record:\n",
    "                records.append(record)\n",
    "                \n",
    "    driver.close()\n",
    "    \n",
    "    # save the data to a csv file\n",
    "    with open(\"data_analyst.csv\", \"w\", newline =\"\", encoding = \"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Book\", \"Price\", \"Rating\", \"Url\"])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b95ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "main(\"data analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596e572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
